services:
  postgres:
    image: postgres:16-alpine
    container_name: dapp-postgres
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/db/data:/mnt/isic_csv_data
    environment:
      POSTGRES_DB: ${DB_NAME:-dapp_db}
      POSTGRES_USER: ${DB_USER:-dapp_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-dapp_password}
    ports:
      - '5432:5432'
    healthcheck:
      test:
        - CMD-SHELL
        - pg_isready -U ${DB_USER:-dapp_user} -d ${DB_NAME:-dapp_db}
      interval: 5s
      timeout: 5s
      retries: 5
  ollama:
    image: ollama/ollama:latest
    container_name: dapp-ollama
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - '11434:11434'
    command: serve
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: dapp-backend
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./backend:/app
      - ./frontend/dist:/app/frontend_dist:ro
      - ./cloudflared.env:/cloudflared.env
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - PORT=${PORT:-8000}
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-dapp_db}
      - DB_USER=${DB_USER:-dapp_user}
      - DB_PASSWORD=${DB_PASSWORD:-dapp_password}
      - >-
        DATABASE_URL=postgresql://${DB_USER:-dapp_user}:${DB_PASSWORD:-dapp_password}@postgres:5432/${DB_NAME:-dapp_db}
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5:7b}
      - OLLAMA_EMBEDDINGS_MODEL=${OLLAMA_EMBEDDINGS_MODEL:-qwen2.5:7b}
      - FRONTEND_URL=http://localhost:5173
    ports:
      - '8000:8000'
    extra_hosts:
      - host.docker.internal:host-gateway
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: dapp-frontend
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - frontend_node_modules:/app/node_modules
    ports:
      - '5173:5173'
    command: yarn run dev -- --host 0.0.0.0
  ollama-setup:
    image: curlimages/curl:latest
    container_name: dapp-ollama-setup
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    depends_on:
      - ollama
    restart: on-failure
    command: |
      sh -c "
        echo 'Waiting for Ollama to be ready...'
        until curl -s http://ollama:11434/api/tags >/dev/null; do
          sleep 5
        done
        echo 'Ollama is ready, pulling qwen2.5-7b model...'
        curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"${OLLAMA_MODEL:-qwen2.5:7b}\"}' -H 'Content-Type: application/json'
        echo 'Done!'
      "
  # cloudflared теперь запускается на хосте через start-dapp.sh
  # Это решает проблемы с Docker networking + v2rayN в WSL2
  # Чтобы запустить только Docker сервисы: docker compose up postgres backend frontend
  # Чтобы запустить весь стек: make up или ./start-dapp.sh
  # Туннельные сервисы удалены - переход на Pinata IPFS для Web3 хостинга
volumes:
  postgres_data: null
  ollama_data: null
  backend_node_modules: null
  frontend_node_modules: null
